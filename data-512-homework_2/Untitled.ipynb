{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974cfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python packages \n",
    "import json, time, urllib.parse\n",
    "import requests\n",
    "\n",
    "# packages for data manipulation\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "\n",
    "# packages for visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = (26,12)\n",
    "\n",
    "# package to ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1aa670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<yangj98@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2022',\n",
    "}\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17fd0bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shahjahan Noori</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Shahjahan_Noori</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdul Ghafar Lakanwal</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abdul_Ghafar_Lak...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                                url  \\\n",
       "0        Shahjahan Noori      https://en.wikipedia.org/wiki/Shahjahan_Noori   \n",
       "1  Abdul Ghafar Lakanwal  https://en.wikipedia.org/wiki/Abdul_Ghafar_Lak...   \n",
       "2         Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "3      Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "4            Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "\n",
       "       country  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the politicians name list\n",
    "df = pd.read_csv('politicians_by_country_SEPT.2022.csv - politicians_international_SEPT.2022.csv.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68667dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of politicians Wikipedia article titles\n",
    "ARTICLE_TITLES = df['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035dbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    # Make sure we have an article title\n",
    "    if not article_title: return None\n",
    "    \n",
    "    request_template['titles'] = article_title\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0114fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = []\n",
    "for i in range(0, len(ARTICLE_TITLES), 50):\n",
    "    info = request_pageinfo_per_article(\"|\".join(ARTICLE_TITLES[i:i+50]))\n",
    "    all_info.extend(list(info['query']['pages'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f1ef8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_info\u001b[49m[df_info\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_info' is not defined"
     ]
    }
   ],
   "source": [
    "df_info[df_info.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7eb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The current ORES API endpoint\n",
    "API_ORES_SCORE_ENDPOINT = \"https://ores.wikimedia.org/v3\"\n",
    "# A template for mapping to the URL\n",
    "#API_ORES_SCORE_PARAMS = \"/scores/{context}/{revid}/{model}\"\n",
    "API_ORES_SCORE_PARAMS = \"/scores/{context}/?models={model}&revids={revid}\"\n",
    "\n",
    "# Use some delays so that we do not hammer the API with our requests\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<vpragya@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2022'\n",
    "}\n",
    "\n",
    "# This template lists the basic parameters for making an ORES request\n",
    "ORES_PARAMS_TEMPLATE = {\n",
    "    \"context\": \"enwiki\",        # which WMF project for the specified revid\n",
    "    \"revid\" : \"\",               # the revision to be scored - this will probably change each call\n",
    "    \"model\": \"articlequality\"   # the AI/ML scoring model to apply to the reviewion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, \n",
    "                                   endpoint_url = API_ORES_SCORE_ENDPOINT, \n",
    "                                   endpoint_params = API_ORES_SCORE_PARAMS, \n",
    "                                   request_template = ORES_PARAMS_TEMPLATE,\n",
    "                                   headers = REQUEST_HEADERS,\n",
    "                                   features=False):\n",
    "    # Make sure we have an article revision id\n",
    "    if not article_revid: return None\n",
    "    \n",
    "    # set the revision id into the template\n",
    "    request_template['revid'] = article_revid\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # the features used by the ML model can sometimes be returned as well as scores\n",
    "    if features:\n",
    "        request_url = request_url+\"?features=true\"\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list revision IDs that can be used for this ORES scoring example\n",
    "ARTICLE_REVISIONS = df_info['lastrevid'].map(int).map(str)\n",
    "ARTICLE_REVISIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "all_scores = []\n",
    "for i in range(0, len(ARTICLE_REVISIONS), 50):\n",
    "    score = request_ores_score_per_article(\"|\".join(ARTICLE_REVISIONS[i:i+50]))\n",
    "    keys = list((score['enwiki']['scores'].keys()))\n",
    "    idx.extend(keys)\n",
    "    #print(keys)\n",
    "    all_scores.extend(list(map(lambda key: score['enwiki']['scores'][key]['articlequality']['score']['prediction'], keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the list to dataframe\n",
    "df_scores = pd.DataFrame(list(zip(idx, all_scores)), columns=['lastrevid', 'score'])\n",
    "df_scores['lastrevid'] = df_scores['lastrevid'].astype(int)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(politicians, df_info, left_on='name', right_on='title', how='right').merge(df_scores, on='lastrevid')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e256f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('population_by_country_2022.csv - population_by_country_2022.csv.csv')\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "population['region'] = population.apply(lambda x: x['Geography'] if x['Geography'].isupper() else None, axis = 1)\n",
    "population['region'] = population['region'].fillna(method=\"ffill\")\n",
    "dropIndex = population[(population['Geography'].str.isupper())].index\n",
    "population = population.drop(dropIndex)\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04396827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, population, left_on='country', right_on='Geography', how='outer')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_exist = df[df.isnull().any(axis=1)]['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file in write mode\n",
    "with open(r'./output_data/wp_countries-no_match.txt', 'w') as fp:\n",
    "    for item in not_exist:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df = df.drop(columns=['name', 'url', 'Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'title':'title_name', 'lastrevid':'revision_id', 'score':'article_quality', 'Population (millions)':'population'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./output_data/wp_politicians_by_country.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
